import json
import pandas as pd
import subprocess
import os
import re
import time
from typing import List, Dict, Tuple  # æ–°å¢Tupleå¯¼å…¥

# -------------------------- é…ç½®å‚æ•°ï¼ˆæ ¹æ®éœ€è¦ä¿®æ”¹ï¼‰--------------------------
FIO_CONFIG_PATH = "benchmark.fio"  # ä½ çš„FIOé…ç½®æ–‡ä»¶è·¯å¾„
TEST_RUNS = 3  # è¿è¡Œæ¬¡æ•°ï¼ˆå›ºå®š3æ¬¡ï¼‰
JSON_OUTPUT_PREFIX = "fio_results_run"  # æ¯æ¬¡æµ‹è¯•çš„JSONç»“æœå‰ç¼€ï¼ˆå¦‚fio_results_run1.jsonï¼‰
FINAL_EXCEL_PATH = "fioæµ‹è¯•ç»“æœ_3æ¬¡å‡å€¼æ±‡æ€».xlsx"  # æœ€ç»ˆExcelè¾“å‡ºè·¯å¾„
FIO_COMMAND = ["fio", "--output-format=json"]  # FIOåŸºç¡€å‘½ä»¤
READ_TEST_FILE_CONFIG = "read_test_file.fio"  # åˆ›å»ºæµ‹è¯•æ–‡ä»¶çš„FIOé…ç½®è·¯å¾„
COUNTDOWN_SECONDS = 10  # å€’è®¡æ—¶ç§’æ•°ï¼ˆå¯ä¿®æ”¹ï¼‰


# -------------------------- æ–°å¢ï¼šå€’è®¡æ—¶ç¡®è®¤å‡½æ•° --------------------------
def countdown_confirm(prompt: str) -> bool:
    """
    å€’è®¡æ—¶ç¡®è®¤å‡½æ•°ï¼šé»˜è®¤10ç§’åè¿”å›Trueï¼ˆæ‰§è¡Œï¼‰ï¼ŒæœŸé—´æŒ‰Ctrl+Cå–æ¶ˆè¿”å›False
    :param prompt: æç¤ºä¿¡æ¯
    :return: æ˜¯å¦æ‰§è¡Œï¼ˆTrue=æ‰§è¡Œï¼ŒFalse=å–æ¶ˆï¼‰
    """
    print(f"\n{prompt}")
    print(f"âŒ› å€’è®¡æ—¶ {COUNTDOWN_SECONDS} ç§’åè‡ªåŠ¨å¼€å§‹ï¼ˆæŒ‰ Ctrl+C å–æ¶ˆï¼‰...")
    try:
        for i in range(COUNTDOWN_SECONDS, 0, -1):
            print(f"\rå‰©ä½™ {i} ç§’...", end="", flush=True)
            time.sleep(1)
        print("\rå€’è®¡æ—¶ç»“æŸï¼Œå¼€å§‹æ‰§è¡Œï¼")
        return True
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        return False


# -------------------------- æ–°å¢ï¼šè§£æè¯»å–æµ‹è¯•æ–‡ä»¶é…ç½® --------------------------
def parse_read_test_config() -> Tuple[str, str, int]:  # tuple -> Tuple
    """
    è§£æread_test_file.fioé…ç½®ï¼Œè·å–:
    - ç›®æ ‡ç›®å½•(directory)
    - æ–‡ä»¶å¤§å°(size)
    - å¹¶å‘æ–‡ä»¶æ•°(numjobs)
    """
    if not os.path.exists(READ_TEST_FILE_CONFIG):
        raise FileNotFoundError(f"è¯»å–æµ‹è¯•é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{READ_TEST_FILE_CONFIG}")

    # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ‰€éœ€å‚æ•°
    dir_pattern = re.compile(r"directory\s*=\s*(\S+)", re.IGNORECASE)
    size_pattern = re.compile(r"size\s*=\s*(\S+)", re.IGNORECASE)
    numjobs_pattern = re.compile(r"numjobs\s*=\s*(\d+)", re.IGNORECASE)

    directory = "."  # é»˜è®¤å½“å‰ç›®å½•
    size = "1G"       # é»˜è®¤å¤§å°
    numjobs = 1       # é»˜è®¤æ–‡ä»¶æ•°

    with open(READ_TEST_FILE_CONFIG, "r", encoding="utf-8") as f:
        content = f.read()

        # æå–ç›®å½•
        dir_match = dir_pattern.search(content)
        if dir_match:
            directory = dir_match.group(1).strip()

        # æå–æ–‡ä»¶å¤§å°
        size_match = size_pattern.search(content)
        if size_match:
            size = size_match.group(1).strip()

        # æå–æ–‡ä»¶æ•°é‡
        numjobs_match = numjobs_pattern.search(content)
        if numjobs_match:
            numjobs = int(numjobs_match.group(1).strip())

    # éªŒè¯ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(directory):
        os.makedirs(directory, exist_ok=True)
        print(f"âš ï¸  ç›®å½•ä¸å­˜åœ¨ï¼Œå·²è‡ªåŠ¨åˆ›å»ºï¼š{directory}")

    return directory, size, numjobs


# -------------------------- ä¿®å¤ï¼šè¿è¡Œæµ‹è¯•æ–‡ä»¶åˆ›å»ºï¼ˆå•ä½ç½®æ›´æ–°ï¼Œä¸åˆ·å±ï¼‰--------------------------
def run_create_test_files():
    """è¿è¡Œread_test_file.fioåˆ›å»ºæµ‹è¯•æ–‡ä»¶ï¼ˆå•ä½ç½®æ›´æ–°è¿›åº¦ï¼Œé¿å…åˆ·å±ï¼‰"""
    print("\nğŸ“‚ å¼€å§‹è§£ææµ‹è¯•æ–‡ä»¶é…ç½®...")
    directory, size, numjobs = parse_read_test_config()

    # æ˜¾ç¤ºåˆ›å»ºä¿¡æ¯
    print(f"âœ… æµ‹è¯•æ–‡ä»¶é…ç½®è§£æå®Œæˆï¼š")
    print(f"   - ç›®æ ‡è·¯å¾„ï¼š{directory}")
    print(f"   - æ–‡ä»¶å¤§å°ï¼š{size}")
    print(f"   - æ–‡ä»¶æ•°é‡ï¼š{numjobs}ä¸ªï¼ˆtestfile.0 ~ testfile.{numjobs-1}ï¼‰")

    # å€’è®¡æ—¶ç¡®è®¤
    if not countdown_confirm("â“ æ˜¯å¦åˆ›å»ºè¿™äº›æµ‹è¯•æ–‡ä»¶ï¼Ÿ"):
        return

    # æ„å»ºå‘½ä»¤ï¼šæ·»åŠ  --eta=alwaysï¼ˆå¼ºåˆ¶æ˜¾ç¤ºè¿›åº¦ï¼‰+ --group_reportingï¼ˆç®€åŒ–è¾“å‡ºï¼‰
    command = ["fio", "--eta=always", "--group_reporting", READ_TEST_FILE_CONFIG]
    print(f"\nğŸ“Œ å¼€å§‹åˆ›å»ºæµ‹è¯•æ–‡ä»¶...")
    print(f"å‘½ä»¤ï¼š{' '.join(command)}")
    print("ğŸ“Š FIOè¿›åº¦")
    print("-" * 80)
    print(f"{'è¿›åº¦ %':<6} {'è¯»å†™æ¨¡å¼':<8} {'å†™å…¥å¸¦å®½':<12} {'IOPS':<12} {'å‰©ä½™æ—¶é—´':<12}")
    print("-" * 80)

    try:
        process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            encoding="utf-8",
            bufsize=1,
            universal_newlines=True  # text=True -> universal_newlines=Trueï¼ˆ3.6å…¼å®¹ï¼‰
        )

        # å®æ—¶è¯»å–è¾“å‡ºï¼Œåªæå–è¿›åº¦è¡Œå¹¶è¦†ç›–æ›´æ–°
        while process.poll() is None:
            line = process.stdout.readline()
            if not line:
                continue

            # åªå¤„ç†åŒ…å«è¿›åº¦ä¿¡æ¯çš„è¡Œï¼ˆåŒ¹é… "Jobs: " ä¸”åŒ…å« "[W(8)]" æˆ–ç±»ä¼¼æ¨¡å¼ï¼‰
            if "Jobs:" in line and "[" in line and "]" in line:
                # ç”¨æ­£åˆ™æå–å…³é”®ä¿¡æ¯ï¼šè¿›åº¦ç™¾åˆ†æ¯”ã€å¸¦å®½ã€IOPSã€å‰©ä½™æ—¶é—´
                progress_pattern = re.search(r"\[(\d+.\d+)%\]", line)
                bw_pattern = re.search(r"w=(\d+MiB/s)", line)
                iops_pattern = re.search(r"w=(\d+ IOPS)", line)
                eta_pattern = re.search(r"eta (\d+m:\d+s)", line)

                # æå–ä¿¡æ¯ï¼ˆæ— åŒ¹é…åˆ™æ˜¾ç¤ºé»˜è®¤å€¼ï¼‰
                progress = progress_pattern.group(1) if progress_pattern else "0.0"
                bw = bw_pattern.group(1) if bw_pattern else "0MiB/s"
                iops = iops_pattern.group(1) if iops_pattern else "0 IOPS"
                eta = eta_pattern.group(1) if eta_pattern else "æœªçŸ¥"

                # ç”¨ \r è¦†ç›–å½“å‰è¡Œï¼Œend="" ä¸æ¢è¡Œï¼Œflush=True å¼ºåˆ¶åˆ·æ–°
                print(f"\r{progress:<8} {'å†™å…¥':<10} {bw:<16} {iops:<12} {eta:<12}", end="", flush=True)

        # æ£€æŸ¥è¿”å›ç 
        returncode = process.wait()
        if returncode != 0:
            raise subprocess.CalledProcessError(returncode, command)

        # è¿›åº¦æ›´æ–°å®Œæˆåï¼Œæ¢è¡Œå¹¶æ‰“å°ç»“æœ
        print("\n" + "-" * 80)
        print(f"âœ… æµ‹è¯•æ–‡ä»¶åˆ›å»ºå®Œæˆï¼Œè·¯å¾„ï¼š{directory}")
    except subprocess.CalledProcessError as e:
        print("\n" + "-" * 80)
        print(f"âŒ æµ‹è¯•æ–‡ä»¶åˆ›å»ºå¤±è´¥ï¼")
        raise
    except Exception as e:
        print("\n" + "-" * 80)
        print(f"âŒ æ‰§è¡Œå¼‚å¸¸ï¼š{str(e)}")
        raise


# -------------------------- åŸæœ‰è§£æFIOé…ç½®æ–‡ä»¶å‡½æ•° --------------------------
def parse_fio_config() -> Tuple[int, int, int, int]:  # tuple -> Tuple
    """åŸæœ‰å‡½æ•°ä¿æŒä¸å˜"""
    if not os.path.exists(FIO_CONFIG_PATH):
        raise FileNotFoundError(f"FIOé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{FIO_CONFIG_PATH}")

    time_pattern = re.compile(r"(runtime|ramp_time)\s*=\s*(\d+)([smh]?)", re.IGNORECASE)
    job_pattern = re.compile(r"^\s*\[(?!global)\w+", re.MULTILINE)

    runtime = 0
    ramp_time = 0
    job_count = 0

    with open(FIO_CONFIG_PATH, "r", encoding="utf-8") as f:
        content = f.read()

        matches = time_pattern.findall(content)
        for key, value, unit in matches:
            value = int(value)
            if unit.lower() == "m":
                value *= 60
            elif unit.lower() == "h":
                value *= 3600

            if key.lower() == "runtime":
                runtime = value
            elif key.lower() == "ramp_time":
                ramp_time = value

        jobs = job_pattern.findall(content)
        job_count = len(jobs)

    if runtime == 0:
        runtime = 30
        print(f"âš ï¸  æœªåœ¨é…ç½®æ–‡ä»¶ä¸­æ‰¾åˆ°runtimeï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼š{runtime}s")
    if ramp_time == 0:
        ramp_time = 5
        print(f"âš ï¸  æœªåœ¨é…ç½®æ–‡ä»¶ä¸­æ‰¾åˆ°ramp_timeï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼š{ramp_time}s")
    if job_count == 0:
        raise ValueError("âŒ æœªåœ¨é…ç½®æ–‡ä»¶ä¸­æ‰¾åˆ°ä»»ä½•Jobï¼ˆæ ¼å¼åº”ä¸º[job_name]ï¼‰")

    single_job_duration = runtime + ramp_time
    return runtime, ramp_time, single_job_duration, job_count


# -------------------------- åŸæœ‰å…¶ä»–å‡½æ•°ä¿æŒä¸å˜ --------------------------
def calculate_total_estimated_time(single_job_duration: int, job_count: int, test_runs: int) -> str:
    total_seconds = single_job_duration * job_count * test_runs
    hours = total_seconds // 3600
    minutes = (total_seconds % 3600) // 60
    seconds = total_seconds % 60

    if hours > 0:
        return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ{seconds}ç§’"
    elif minutes > 0:
        return f"{minutes}åˆ†é’Ÿ{seconds}ç§’"
    else:
        return f"{seconds}ç§’"


# -------------------------- ä¿®å¤ï¼šrun_fio_testï¼ˆå•ä½ç½®æ›´æ–°ï¼Œä¸åˆ·å±ï¼‰--------------------------
def run_fio_test(run_index: int) -> str:
    json_path = f"{JSON_OUTPUT_PREFIX}{run_index}.json"
    # å‘½ä»¤ï¼š--eta=alwaysï¼ˆè¿›åº¦ï¼‰+ --group_reportingï¼ˆç®€åŒ–è¾“å‡ºï¼‰+ ä¿ç•™JSONè¾“å‡º
    full_command = FIO_COMMAND + ["--eta=always", "--group_reporting", "--output", json_path, FIO_CONFIG_PATH]

    print(f"\nğŸ“Œ å¼€å§‹ç¬¬{run_index}æ¬¡FIOæµ‹è¯•...")
    print(f"å‘½ä»¤ï¼š{' '.join(full_command)}")
    print("ğŸ“Š FIOè¿›åº¦")
    print("-" * 80)
    print(f"{'è¿›åº¦ %':<6} {'è¯»å†™æ¨¡å¼':<8} {'å†™å…¥å¸¦å®½':<12} {'IOPS':<12} {'å‰©ä½™æ—¶é—´':<12}")
    print("-" * 80)

    try:
        process = subprocess.Popen(
            full_command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            encoding="utf-8",
            bufsize=1,
            universal_newlines=True  # text=True -> universal_newlines=Trueï¼ˆ3.6å…¼å®¹ï¼‰
        )

        # å®æ—¶è¯»å–è¾“å‡ºï¼Œåªæå–è¿›åº¦è¡Œå¹¶è¦†ç›–æ›´æ–°
        while process.poll() is None:
            line = process.stdout.readline()
            if not line:
                continue

            # DEBUGæµ‹è¯•ç”¨
            # line = "Jobs: 1 (f=1): [W(1),P(259)][0.3%][w=1550KiB/s][w=12 IOPS][eta 35m:00s]"
            # line = "Jobs: 1(f=1): [_(1), R(1), P(1)][53.8 %][r = 543MiB / s][r = 4340IOPS][eta 00m: 49s]"
            # line = "Jobs: 1 (f=1): [m(1)][25.7%][r=121MiB/s,w=51.8MiB/s][r=30.9k,w=13.3k IOPS][eta 00m:26s]"

            if "Jobs:" in line and "[" in line and "]":
                # æå–è¯»å†™æ¨¡å¼ï¼ˆæ”¯æŒWå†™ã€Rè¯»ã€mæ··åˆï¼Œä»¥åŠåŒ…å«å…¶ä»–å­—ç¬¦çš„æƒ…å†µï¼‰
                rw_pattern = re.search(r"\[([^]]*)([WRm])\([^)]*\)", line)

                # æå–è¿›åº¦ç™¾åˆ†æ¯”ï¼ˆæ”¯æŒç©ºæ ¼å’Œå°æ•°ç‚¹ï¼‰
                progress_pattern = re.search(r"\[(\d+\.?\d*)\s*%\]", line)

                # æå–å¸¦å®½ï¼ˆæ”¯æŒr=, w=, å„ç§å•ä½ï¼Œä»¥åŠå¯èƒ½çš„ç©ºæ ¼ï¼‰
                bw_pattern = re.search(r"\[(?:r|w)=(\d+\.?\d*\s*[KM]?i?B/s)\]", line)

                # æå–IOPSï¼ˆæ”¯æŒr=, w=, kå•ä½ï¼Œä»¥åŠå¯èƒ½çš„ç©ºæ ¼ï¼‰
                iops_pattern = re.search(r"\[(?:r|w)=(\d+\.?\d*\s*[k]?\s*IOPS)\]", line)

                # æå–å‰©ä½™æ—¶é—´ï¼ˆæ”¯æŒç©ºæ ¼ï¼‰
                eta_pattern = re.search(r"eta\s*(\d+m:\d+s)", line)

                # è§£æä¿¡æ¯
                rw_mode = rw_pattern.group(2) if rw_pattern else "æœªçŸ¥"
                progress = progress_pattern.group(1) if progress_pattern else "0.0"
                bw = bw_pattern.group(1).strip() if bw_pattern else "0B/s"
                iops = iops_pattern.group(1).strip() if iops_pattern else "0 IOPS"
                eta = eta_pattern.group(1) if eta_pattern else "æœªçŸ¥"

                # è½¬æ¢è¯»å†™æ¨¡å¼ä¸ºä¸­æ–‡ï¼ˆmè½¬ä¸ºæ··åˆï¼‰
                rw_cn = {"R": "è¯»å–", "W": "å†™å…¥", "m": "æ··åˆ"}.get(rw_mode, "æœªçŸ¥")

                # è¦†ç›–å½“å‰è¡Œæ›´æ–°è¿›åº¦
                # print(f"\rè¿›åº¦: {progress:>6}% | æ¨¡å¼: {rw_cn:<6} | å¸¦å®½: {bw:<12} | IOPS: {iops:<10} | å‰©ä½™: {eta:<10}",end="", flush=True)
                print(f"\r{progress:<8} {rw_cn:<10} {bw:<16} {iops:<12} {eta:<12}", end="", flush=True)

        # æ£€æŸ¥è¿”å›ç 
        returncode = process.wait()
        if returncode != 0:
            raise subprocess.CalledProcessError(returncode, full_command)

        # å®Œæˆåæ¢è¡Œ
        print("\n" + "-" * 80)
        print(f"âœ… ç¬¬{run_index}æ¬¡æµ‹è¯•å®Œæˆï¼Œç»“æœæ–‡ä»¶ï¼š{json_path}")
        return json_path
    except subprocess.CalledProcessError as e:
        print("\n" + "-" * 80)
        print(f"âŒ ç¬¬{run_index}æ¬¡æµ‹è¯•å¤±è´¥ï¼")
        raise
    except Exception as e:
        print("\n" + "-" * 80)
        print(f"âŒ æ‰§è¡Œå¼‚å¸¸ï¼š{str(e)}")
        raise


def extract_fio_metrics(json_path: str) -> List[Dict]:
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    jobs = data.get("jobs", [])
    if not jobs:
        print(f"âš ï¸ {json_path} ä¸­æœªæ‰¾åˆ°jobsæ•°æ®ï¼Œè·³è¿‡è¯¥æ–‡ä»¶")
        return []

    result_list = []
    for job in jobs:
        job_opts = job.get("job options", {})
        base_info = {
            "groupid": job.get("groupid", ""),
            "æµ‹è¯•åç§°": job.get("jobname", ""),
            "æµ‹è¯•æè¿°": job_opts.get("description", job.get("desc", "")),
            "è¯»å†™æ¨¡å¼": job_opts.get("rw", ""),
            "å—å¤§å°": job_opts.get("bs", ""),
            "IOé˜Ÿåˆ—æ·±åº¦": job_opts.get("iodepth", ""),
            "å¹¶å‘jobæ•°": job_opts.get("numjobs", "")
        }

        read_data = job.get("read", {})
        write_data = job.get("write", {})

        metrics = {
            "è¯»å–é‡(MB)": round(read_data.get("io_kbytes", 0) / 1024, 2),
            "å†™å…¥é‡(MB)": round(write_data.get("io_kbytes", 0) / 1024, 2),
            "è¯»å–å¸¦å®½(MB/s)": round(read_data.get("bw_mean", 0) / 1024, 2),
            "å†™å…¥å¸¦å®½(MB/s)": round(write_data.get("bw_mean", 0) / 1024, 2),
            "è¯»å–IOPS(æ¬¡/ç§’)": round(read_data.get("iops_mean", 0.0), 2),
            "å†™å…¥IOPS(æ¬¡/ç§’)": round(write_data.get("iops_mean", 0.0), 2),
            "æ€»å»¶è¿Ÿå‡å€¼(æ¯«ç§’)": round(read_data.get("lat_ns", {}).get("mean", 0) / 1e6, 2),
            "CPUæ€»ä½¿ç”¨ç‡(%)": round(job.get("usr_cpu", 0) + job.get("sys_cpu", 0), 2)
        }

        result_list.append({**base_info, **metrics})

    print(f"ğŸ“Š ä»{json_path}æå–åˆ° {len(result_list)} ä¸ªJobçš„æŒ‡æ ‡")
    return result_list


def calculate_mean_metrics(all_runs_data: List[List[Dict]]) -> pd.DataFrame:
    combined_data = []
    for run_idx, run_data in enumerate(all_runs_data, 1):
        for job_data in run_data:
            job_data["æµ‹è¯•æ¬¡æ•°"] = run_idx
            combined_data.append(job_data)

    df_combined = pd.DataFrame(combined_data)
    group_keys = ["groupid", "æµ‹è¯•åç§°", "æµ‹è¯•æè¿°", "è¯»å†™æ¨¡å¼", "å—å¤§å°", "IOé˜Ÿåˆ—æ·±åº¦", "å¹¶å‘jobæ•°"]
    metric_cols = [
        "è¯»å–é‡(MB)", "å†™å…¥é‡(MB)", "è¯»å–å¸¦å®½(MB/s)", "å†™å…¥å¸¦å®½(MB/s)",
        "è¯»å–IOPS(æ¬¡/ç§’)", "å†™å…¥IOPS(æ¬¡/ç§’)", "æ€»å»¶è¿Ÿå‡å€¼(æ¯«ç§’)", "CPUæ€»ä½¿ç”¨ç‡(%)"
    ]

    df_mean = df_combined.groupby(group_keys)[metric_cols].mean().round(2).reset_index()
    return df_mean


def generate_final_excel(
        all_runs_data: List[List[Dict]],
        df_mean: pd.DataFrame,
        excel_path: str
):
    column_order = [
        "groupid", "æµ‹è¯•åç§°", "æµ‹è¯•æè¿°", "è¯»å†™æ¨¡å¼", "å—å¤§å°", "IOé˜Ÿåˆ—æ·±åº¦", "å¹¶å‘jobæ•°",
        "è¯»å–é‡(MB)", "å†™å…¥é‡(MB)",
        "è¯»å–å¸¦å®½(MB/s)", "å†™å…¥å¸¦å®½(MB/s)",
        "è¯»å–IOPS(æ¬¡/ç§’)", "å†™å…¥IOPS(æ¬¡/ç§’)",
        "æ€»å»¶è¿Ÿå‡å€¼(æ¯«ç§’)", "CPUæ€»ä½¿ç”¨ç‡(%)"
    ]

    with pd.ExcelWriter(excel_path, engine="openpyxl") as writer:
        df_mean = df_mean[column_order]
        df_mean.to_excel(writer, sheet_name="å‡å€¼æ±‡æ€»", index=False)

        for run_idx, run_data in enumerate(all_runs_data, 1):
            sheet_name = f"ç¬¬{run_idx}æ¬¡"
            df_run = pd.DataFrame(run_data)[column_order]
            df_run.to_excel(writer, sheet_name=sheet_name, index=False)

        # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
        for sheet_name in writer.sheets:
            worksheet = writer.sheets[sheet_name]
            for column in worksheet.columns:
                max_length = max(len(str(cell.value)) if cell.value else 0 for cell in column)
                adjusted_width = min(max_length + 3, 25)  # æœ€å¤§å®½åº¦é™åˆ¶ä¸º25
                worksheet.column_dimensions[column[0].column_letter].width = adjusted_width

    print(f"\nğŸ‰ æœ€ç»ˆExcelæ–‡ä»¶å·²ç”Ÿæˆï¼š{excel_path}")
    print(f"ğŸ“‹ åŒ…å«å·¥ä½œè¡¨ï¼šå‡å€¼æ±‡æ€»ã€ç¬¬1æ¬¡ã€ç¬¬2æ¬¡ã€ç¬¬3æ¬¡")


# -------------------------- ä¸»æµç¨‹ï¼ˆå®Œæ•´æ— æˆªæ–­ï¼‰--------------------------
def main():
    print("=" * 60)
    print("ğŸš€ å¼€å§‹FIOæµ‹è¯•è‡ªåŠ¨åŒ–æµç¨‹ï¼ˆ3æ¬¡è¿è¡Œ+å‡å€¼æ±‡æ€»ï¼‰")
    print(f"æµ‹è¯•æ–‡ä»¶é…ç½®ï¼š{READ_TEST_FILE_CONFIG}")
    print(f"FIOé…ç½®æ–‡ä»¶ï¼š{FIO_CONFIG_PATH}")
    print(f"æœ€ç»ˆExcelè¾“å‡ºï¼š{FINAL_EXCEL_PATH}")
    print("=" * 60)

    try:
        # æ­¥éª¤1ï¼šè¿è¡Œæµ‹è¯•æ–‡ä»¶åˆ›å»ºï¼ˆå•ä½ç½®æ›´æ–°ï¼‰
        run_create_test_files()

        # æ­¥éª¤2ï¼šè§£æFIOé…ç½®å¹¶å€’è®¡æ—¶ç¡®è®¤æµ‹è¯•
        print("\nğŸ“Š æ­£åœ¨è§£æFIOé…ç½®æ–‡ä»¶ï¼Œè®¡ç®—é¢„ä¼°æµ‹è¯•æ—¶é•¿...")
        runtime, ramp_time, single_job_duration, job_count = parse_fio_config()
        total_estimated_time = calculate_total_estimated_time(
            single_job_duration, job_count, TEST_RUNS
        )

        print(f"âœ… é…ç½®è§£æå®Œæˆï¼š")
        print(f"   - å•ä¸ªJobè€—æ—¶ï¼š{single_job_duration}ç§’ï¼ˆruntime={runtime}s + ramp_time={ramp_time}sï¼‰")
        print(f"   - æ€»Jobæ•°é‡ï¼š{job_count}ä¸ª")
        print(f"   - æµ‹è¯•æ¬¡æ•°ï¼š{TEST_RUNS}æ¬¡")
        print(f"   - æ€»é¢„ä¼°æ—¶é•¿ï¼š{total_estimated_time}ï¼ˆå®é™…æ—¶é•¿å¯èƒ½å› ç³»ç»Ÿè´Ÿè½½ç•¥æœ‰å·®å¼‚ï¼‰")

        # å€’è®¡æ—¶ç¡®è®¤å¼€å§‹æµ‹è¯•
        if not countdown_confirm("â“ æ˜¯å¦ç»§ç»­æ‰§è¡ŒFIOæµ‹è¯•ï¼Ÿ"):
            print("ğŸ›‘ æµ‹è¯•å·²å–æ¶ˆ")
            return

        # æ­¥éª¤3ï¼šæ‰§è¡Œå¤šæ¬¡FIOæµ‹è¯•ï¼ˆå•ä½ç½®æ›´æ–°ï¼‰
        json_paths = []
        for run_idx in range(1, TEST_RUNS + 1):
            json_path = run_fio_test(run_idx)
            json_paths.append(json_path)

        # æ­¥éª¤4ï¼šæå–æŒ‡æ ‡ã€è®¡ç®—å‡å€¼ã€ç”ŸæˆExcel
        all_runs_data = []
        for json_path in json_paths:
            run_data = extract_fio_metrics(json_path)
            if run_data:
                all_runs_data.append(run_data)

        print("\nğŸ“ˆ å¼€å§‹è®¡ç®—3æ¬¡æµ‹è¯•å‡å€¼...")
        df_mean = calculate_mean_metrics(all_runs_data)

        generate_final_excel(all_runs_data, df_mean, FINAL_EXCEL_PATH)

        # æ­¥éª¤5ï¼šåˆ é™¤ä¸­é—´æ–‡ä»¶ï¼ˆä¿ç•™æ‰‹åŠ¨ç¡®è®¤ï¼‰
        if input("\nâ“ æ˜¯å¦åˆ é™¤ä¸­é—´JSONç»“æœæ–‡ä»¶ï¼Ÿ(y/nï¼Œé»˜è®¤n) ").lower() == "y":
            for json_path in json_paths:
                os.remove(json_path)
                print(f"ğŸ—‘ï¸ åˆ é™¤æ–‡ä»¶ï¼š{json_path}")

        print("\nâœ… å…¨éƒ¨æµç¨‹å®Œæˆï¼")

    except Exception as e:
        print(f"\nâŒ æµç¨‹æ‰§è¡Œå¤±è´¥ï¼š{str(e)}")
        raise


if __name__ == "__main__":
    main()